{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAM():\n",
    "    '''A class to extract data from the Victoria and Albert Museum API.\n",
    "\n",
    "    See more information in: \n",
    "    https://developers.vam.ac.uk/guide/v2/search/introduction.html\n",
    "\n",
    "    https://api.vam.ac.uk/docs#/\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    object_type : str\n",
    "        Name of object type that will be searched\n",
    "\n",
    "    year_accession_from : int\n",
    "        Filter from which year the object was accessioned into the museum collection\n",
    "\n",
    "    year_accession_to : int\n",
    "        Filter until which year the object was accessioned into the museum collection\n",
    "\n",
    "    n_page : int, minLength: 1, maxLength: 100\n",
    "        Number of pages in the return of API\n",
    "\n",
    "    page_size : int, minLength: 1, maxLength: 100\n",
    "        Size of page in the return of API\n",
    "\n",
    "    chunksize : int\n",
    "        Range of years for each request (breaking an big request in smaller pieces)\n",
    "\n",
    "    cursor_from : int\n",
    "        Parameter used to iterate the whole range of years\n",
    "\n",
    "    cursor_to : int\n",
    "        Parameter used to iterate the whole range of years\n",
    "\n",
    "    output : str\n",
    "        Output path to the extracted data\n",
    "    '''\n",
    "\n",
    "    def __init__(self, object_type = None, year_accession_from = None, year_accession_to = None, n_page = None, page_size = None, chunksize = None, cursor_from = None, cursor_to = None, output = None):\n",
    "        self.object_type = object_type \n",
    "        self.year_accession_from = year_accession_from \n",
    "        self.year_accession_to = year_accession_to\n",
    "        self.page_size = page_size\n",
    "        self.chunksize = chunksize\n",
    "        self.cursor_from = self.year_accession_from\n",
    "        self.cursor_to = self.year_accession_from + self.chunksize\n",
    "        self.n_page = n_page\n",
    "        self.output = output\n",
    "\n",
    "    def extract(self):\n",
    "        '''\n",
    "        Execute the requests to the API to extract the data\n",
    "        '''\n",
    "        # Loop to interate between selected dates, jumping through selected chunksize\n",
    "        while self.cursor_from <= self.year_accession_to:\n",
    "\n",
    "            # Create empty list \n",
    "            lst_result = []\n",
    "            \n",
    "            # Loop to interate through the pages\n",
    "            for page in tqdm(range(1,self.n_page + 1)):\n",
    "            \n",
    "                # Defining URL\n",
    "                url = f\"https://api.vam.ac.uk/v2/objects/search?q_object_type={self.object_type}&year_accessioned_from={self.cursor_from}&year_accessioned_to={self.cursor_to}&order_sort=asc&page={page}&page_size={self.page_size}&cluster_size=20&response_format=json\"\n",
    "\n",
    "                # Requesting data\n",
    "                resp = requests.get(url,headers= {'accept': 'application/json'})\n",
    "\n",
    "                # Selecting data in JSON       \n",
    "                temp_json = resp.json()['records']\n",
    "                \n",
    "                # Verifying if there's no more values and finishing the loop\n",
    "                if temp_json == []:\n",
    "                    \n",
    "                    break\n",
    "\n",
    "                else: \n",
    "                    # Appending in a list\n",
    "                    lst_result += temp_json\n",
    "\n",
    "            # Normalizing json and creating DataFrame\n",
    "            result = pd.json_normalize(lst_result)\n",
    "\n",
    "            # Exporting results\n",
    "            result.to_csv(f'{self.output}/VAM_{self.cursor_from}-{self.cursor_to}.csv',index=False)\n",
    "\n",
    "            print(f'\\n Concluded extraction From: {self.cursor_from} - To: {self.cursor_to} \\n')\n",
    "\n",
    "            # Changing period of a time\n",
    "            self.cursor_from = self.cursor_to + 1\n",
    "            self.cursor_to += self.chunksize\n",
    "\n",
    "        return 'Files created'\n",
    "\n",
    "    def compile_files(self):\n",
    "        '''\n",
    "        Read the output path and aggregate the csv archives in one archive\n",
    "        '''\n",
    "        # Creating empty DataFrame\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        # Interating dir to compile files\n",
    "        for archive in listdir(self.output):\n",
    "            \n",
    "            # Verifying if is an target archive\n",
    "            if archive.startswith('VAM_'):\n",
    "                \n",
    "                # Reading information\n",
    "                temp_df = pd.read_csv(f'{self.output}/{archive}')\n",
    "\n",
    "                # Appending to DF\n",
    "                df = df.append(temp_df)\n",
    "            else:\n",
    "                # Do nothing\n",
    "                pass\n",
    "        \n",
    "        # Exporting aggregated result\n",
    "        df.to_csv(f'{self.output}/Agg_VAM_{self.year_accession_from}-{self.year_accession_to}.csv',index=False)\n",
    "\n",
    "        print('\\n Files aggregated \\n')\n",
    "\n",
    "        return 'Files aggregated'\n",
    "\n",
    "    def run(self):\n",
    "        '''Function to run the whole process of extraction'''\n",
    "        self.extract()\n",
    "        self.compile_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vam = VAM(object_type = 'Painting', year_accession_from = 1850, year_accession_to = 2021, n_page = 100, page_size = 100, chunksize = 50, output = './Output')"
   ]
  },
  {
   "source": [
    "%%time\n",
    "vam.run()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}